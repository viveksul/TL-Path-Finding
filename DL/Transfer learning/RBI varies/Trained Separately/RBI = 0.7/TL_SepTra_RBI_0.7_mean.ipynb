{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our project\n",
    "\n",
    "# Here we are building a mulitple input mixed data model that takes in the 3 inputs seperately. RBI, chaneel matrices remain \n",
    "# seperate but now instead of giving Spectrum Occupancy matrix as input we give only NSA and instead of Src Des matrix we \n",
    "# just give Src and Des node id. The NSA and Src_Des input are given in two different branches, in the next model they will \n",
    "# be given together on one branch. The output power are indices rather matrices. So its an Nx1 vector.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# number of iterations the matlab code ran or the number of times the network is simulated\n",
    "itr = 50000\n",
    "# Number of iterations the test data generation matlab code ran or the number of times the network is simulated\n",
    "itr_test = 2000\n",
    "# number of nodes in the network\n",
    "N = 30\n",
    "# We scale the non zero values of output power so that there is some sizable error if the model outputs a zero matrix\n",
    "scaling_parameter = 1\n",
    "\n",
    "# Reading the RBI data\n",
    "df = pd.read_csv(\"Data for RBI TL 0.7 mean 50000_itr(N=30)/Data_rbi_vectors.csv\")\n",
    "#print(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_1 = df.to_numpy()\n",
    "#print(tem)\n",
    "X_1.shape\n",
    "\n",
    "#Just for the 1332 dataset as the last array will be nans\n",
    "#tem = tem[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94562fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=list(range(0, itr))\n",
    "# X_1 = np.zeros((itr,N))\n",
    "# for i in a:\n",
    "#     X_1[i:] = tem[i:]\n",
    "#X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the channel data\n",
    "df1 = pd.read_csv(\"Data for RBI TL 0.7 mean 50000_itr(N=30)/Data_channel_matrices.csv\")\n",
    "#print(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_2 = df1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2.reshape((itr,N,N))\n",
    "#print(X_2)\n",
    "X_2 = np.nan_to_num(X_2)\n",
    "#X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6164f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Source_Destination_info data\n",
    "df2 = pd.read_csv(\"Data for RBI TL 0.7 mean 50000_itr(N=30)/Data_Source_Destination_info_matrix(only Src Des).csv\")\n",
    "#print(df2)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b680ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_3 = df2.to_numpy()\n",
    "#print(X_3)\n",
    "X_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = X_3.astype(np.float64)\n",
    "print(X_3.dtype)\n",
    "#print(X_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Spectrum_occupancy data, i.e, NSA\n",
    "df3 = pd.read_csv(\"Data for RBI TL 0.7 mean 50000_itr(N=30)/Data_spectrum_matrix.csv\")\n",
    "#print(df3)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ada01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_4 = df3.to_numpy()\n",
    "#print(X_4)\n",
    "X_4.shape\n",
    "\n",
    "# Its already in float64 so no need to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the output power data\n",
    "df4 = pd.read_csv(\"Data for RBI TL 0.7 mean 50000_itr(N=30)/Data_output1.csv\")\n",
    "#print(df4)\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5598e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_5 = df4.to_numpy()\n",
    "#print(X_5)\n",
    "print(X_5.shape)\n",
    "X_5 = np.nan_to_num(X_5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88b452e7",
   "metadata": {},
   "source": [
    "## Testing Cell, just to work out code to convert the (1, 30) output to (1, 6)\n",
    "\n",
    "a=list(range(0, itr))\n",
    "max1 = 0\n",
    "count = 0\n",
    "max_path = np.zeros(30)\n",
    "max_path_ind = 0\n",
    "X_5_new = np.zeros(6)\n",
    "for i in a:\n",
    "    #print(\"Original\")\n",
    "    #print(X_5[i])\n",
    "    temp = X_5[i]\n",
    "    #print(\"Non zero elements\")\n",
    "    #print(temp[np.nonzero(temp)])\n",
    "    #print(\"Length of nonzero array\")\n",
    "    temp_ind = len(temp[np.nonzero(temp)])\n",
    "    #print(temp_ind)\n",
    "    if temp_ind > max1:\n",
    "        max1 = temp_ind\n",
    "        max_path = temp\n",
    "        max_path_ind = i\n",
    "        if max1 > 6:\n",
    "            count = count + 1\n",
    "            print(temp)\n",
    "            print(i)\n",
    "            \n",
    "print(\"max nonzero length\")\n",
    "print(max1)\n",
    "print(max_path)\n",
    "print(max_path_ind)\n",
    "print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell converts each of the (1,30) output of y_data to (1,6)\n",
    "\n",
    "a=list(range(0, itr))\n",
    "max1 = 0\n",
    "count = 0\n",
    "maxlen = 0\n",
    "max_path = np.zeros(30)\n",
    "max_path_ind = 0\n",
    "X_5_new = np.zeros((itr,6))\n",
    "for i in a:\n",
    "    temp = X_5[i]\n",
    "    maxlen = len(temp[np.nonzero(temp)])\n",
    "    if maxlen > 6:\n",
    "        X_5_new[i,:] = temp[0:6]\n",
    "        temp_non_zero = temp[np.nonzero(temp)]\n",
    "        X_5_new[i,5] = temp_non_zero[-1]\n",
    "        continue\n",
    "    X_5_new[i,:] = temp[0:6]\n",
    "    #print(\"original\")\n",
    "    #print(X_5[i])\n",
    "X_5_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: for 33569 itr data  the 150th and 7128 paths have length > 6 , ie, [ 6. 23. 27.  3. 15. 17. 18.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] and [30.  7.  8. 16.  3. 25. 12. 21.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e513a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = X_5_new.astype(np.float64)\n",
    "print(y_data.dtype)\n",
    "#print(y_data_temp)\n",
    "y_data.shape\n",
    "\n",
    "# No need to unravel it as its already a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.dtype, X_2.dtype, X_3.dtype, X_4.dtype, y_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.shape, X_2.shape, X_3.shape, X_4.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling parameter for y_data so model gets greater penalty for error and also since output is sparse\n",
    "\n",
    "y_data = y_data*scaling_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_data to tensor\n",
    "\n",
    "y_data = tf.constant(y_data)\n",
    "print(y_data.shape)\n",
    "#y_data = tf.reshape(y_data, [itr,1,1,N*N])\n",
    "#print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.core import Activation\n",
    "from tensorflow.python.keras.layers.core import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import concatenate\n",
    "#from tensorflow.python.keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating branches of the model\n",
    "\n",
    "# Activations\n",
    "a1 = 'relu'\n",
    "a2 = None\n",
    "\n",
    "# Branch 1, takes RBI vectors as input and processws it\n",
    "\n",
    "rbi_input = Input(shape=(N,))\n",
    "x1 = tf.keras.layers.BatchNormalization()(rbi_input)\n",
    "#x1 = Dropout(0.3)(x1)\n",
    "x1 = Dense(50, activation=a1)(x1)\n",
    "#x1 = Dropout(0.3)(x1)\n",
    "x1 = Dense(50, activation=a1)(x1)\n",
    "#x1 = Dense(1000, activation=a2)(x1)\n",
    "#x1 = Dense(1000, activation=a2)(x1)\n",
    "out_1 = Dense(N, activation=a1)(x1)\n",
    "\n",
    "# Branch 2, takes channel matrix as input and processes it\n",
    "\n",
    "chan_input = Input(shape=(N, N))\n",
    "x2 = tf.keras.layers.BatchNormalization()(chan_input)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(80, activation=a1)(x2)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#x2 = Flatten()(chan_input)\n",
    "x2 = Dense(80, activation=a1)(x2)\n",
    "#x2 = Dense(1000, activation =a2)(x2)\n",
    "#x2 = Dense(1000, activation =a2)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "out_2 = Dense(N*N, activation=a1)(x2)\n",
    "\n",
    "# Branch 3, takes Source Destination info and processes it\n",
    "\n",
    "S_D_input = Input(shape=(2, ))\n",
    "#x3 = Flatten()(S_D_input)\n",
    "x3 = tf.keras.layers.BatchNormalization()(S_D_input)\n",
    "#x3 = Dropout(0.3)(x3)\n",
    "x3 = Dense(10, activation=a1)(x3)\n",
    "#x3 = Dropout(0.2)(x3)\n",
    "#x3 = Dropout(0.3)(x3)\n",
    "x3 = Dense(10, activation=a1)(x3)\n",
    "#x3 = Dropout(0.2)(x3)\n",
    "#x3 = Dense(1000, activation =a2)(x3)\n",
    "#x3 = Dense(1000, activation =a2)(x3)\n",
    "#x3 = Flatten()(x3)\n",
    "out_3 = Dense(10, activation=a1)(x3)\n",
    "\n",
    "# Branch 4, takes Spectrum occupancy info and processes it\n",
    "\n",
    "Spec_input = Input(shape=(1, ))\n",
    "#x4 = Flatten()(Spec_input)\n",
    "x4 = tf.keras.layers.BatchNormalization()(Spec_input)\n",
    "#x4 = Dropout(0.3)(x4)\n",
    "x4 = Dense(20, activation=a1)(x4)\n",
    "#x4 = Dropout(0.3)(x4)\n",
    "x4 = Dense(20, activation=a1)(x4)\n",
    "#x4 = Dense(1000, activation =a2)(x4)\n",
    "#x4 = Dense(1000, activation =a2)(x4)\n",
    "#x4 = Flatten()(x4)\n",
    "out_4 = Dense(10, activation=a1)(x4)\n",
    "\n",
    "# Now we concatenate all the branches \n",
    "\n",
    "concatenated = concatenate([out_1, out_2, out_3, out_4]) ## concatenate the four branches\n",
    "#x5 = Dropout(0.1)(cocatenated)\n",
    "x5 = Dense(100, activation=a1)(concatenated)\n",
    "#x5 = Dropout(0.3)(x5)\n",
    "x5 = Dense(100, activation=a1)(x5)\n",
    "#x5 = Dropout(0.3)(x5)\n",
    "x5 = Dense(100, activation=a1)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "#x5 = Dropout(0.2)(x5)\n",
    "out = Dense(6, activation=a1)(x5)\n",
    "model = Model([rbi_input, chan_input, S_D_input, Spec_input], out, name='Model_3')\n",
    "\n",
    "# Set optimizer\n",
    "\n",
    "#opt = Adam(lr=0.01, decay=1e-6)\n",
    "#sgd = SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "#model.compile(loss='mse',\n",
    "#              optimizer = 'adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mse, # mae is short for mean absolute error\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), # SGD is short for stocastic gradient descent\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#model.compile(loss=tf.keras.losses.mse,\n",
    "#              optimizer=tf.keras.optimizers.Adam(),\n",
    "#              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "# We also measure the time taken to compute\n",
    "t = time.perf_counter()\n",
    "history = model.fit([X_1, X_2, X_3, X_4], y_data, batch_size=32, epochs=100, validation_split = 0.03)\n",
    "t_c = time.perf_counter() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we read the test data to evaluate our model\n",
    "\n",
    "\n",
    "# Reading the Test RBI data\n",
    "df_test = pd.read_csv(\"Test Data for RBI 0.7 mean 2000_itr(N=30)/Test_Data_rbi_vectors.csv\")\n",
    "#print(df_test)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e54ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "tem_test = df_test.to_numpy()\n",
    "#print(tem_test)\n",
    "tem_test.shape\n",
    "X_1_test = tem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc551c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test channel data\n",
    "df1_test = pd.read_csv(\"Test Data for RBI 0.7 mean 2000_itr(N=30)/Test_Data_channel_matrices.csv\")\n",
    "#print(df1_test)\n",
    "df1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_2_test = df1_test.to_numpy()\n",
    "X_2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_test = X_2_test.reshape((itr_test,N,N))\n",
    "#print(X_2_test)\n",
    "X_2_test = np.nan_to_num(X_2_test)\n",
    "#X_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test Source_Destination_info data\n",
    "\n",
    "df2_test = pd.read_csv(\"Test Data for RBI 0.7 mean 2000_itr(N=30)/Test_Data_Source_Destination_info_matrix(only Src Des).csv\")\n",
    "#print(df2_test)\n",
    "df2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c06566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_3_test = df2_test.to_numpy()\n",
    "#print(X_3_test)\n",
    "X_3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_test = X_3_test.astype(np.float64)\n",
    "print(X_3_test.dtype)\n",
    "#print(X_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea766d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test Spectrum_occupancy data, i.e, NSA\n",
    "\n",
    "df3_test = pd.read_csv(\"Test Data for RBI 0.7 mean 2000_itr(N=30)/Test_Data_spectrum_matrix.csv\")\n",
    "#print(df3_test)\n",
    "df3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_4_test = df3_test.to_numpy()\n",
    "#print(X_4_test)\n",
    "X_4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fe49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4_test = X_4_test.astype(np.float64)\n",
    "print(X_4_test.dtype)\n",
    "#print(X_4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test output power data\n",
    "\n",
    "df4_test = pd.read_csv(\"Test Data for RBI 0.7 mean 2000_itr(N=30)/Test_Data_output1.csv\")\n",
    "#print(df4_test)\n",
    "df4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_5_test = df4_test.to_numpy()\n",
    "#print(X_5_test)\n",
    "print(X_5_test.shape)\n",
    "X_5_test = np.nan_to_num(X_5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell converts each of the (1,30) y_data_test output to (1,6)\n",
    "\n",
    "a=list(range(0, itr_test))\n",
    "max1 = 0\n",
    "count = 0\n",
    "maxlen = 0\n",
    "max_path = np.zeros(30)\n",
    "max_path_ind = 0\n",
    "X_5_test_new = np.zeros((itr_test,6))\n",
    "for i in a:\n",
    "    temp = X_5_test[i]\n",
    "    maxlen = len(temp[np.nonzero(temp)])\n",
    "    if maxlen > 6:\n",
    "        X_5_test_new[i,:] = temp[0:6]\n",
    "        temp_non_zero = temp[np.nonzero(temp)]\n",
    "        X_5_test_new[i,5] = temp_non_zero[-1]\n",
    "        continue\n",
    "    X_5_test_new[i,:] = temp[0:6]\n",
    "    #print(\"original\")\n",
    "    #print(X_5[i])\n",
    "X_5_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab61b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_test = X_5_test_new.astype(np.float64)\n",
    "print(y_data_test.dtype)\n",
    "#print(y_data_test)\n",
    "y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test.dtype, X_2_test.dtype, X_3_test.dtype, X_4_test.dtype, y_data_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test.shape, X_2_test.shape, X_3_test.shape, X_4_test.shape, y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test = [X_1_test, X_2_test, X_3_test, X_4_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_data_test to tensor\n",
    "\n",
    "y_data_test = tf.constant(y_data_test)\n",
    "print(y_data_test.shape)\n",
    "#y_data_test = tf.reshape(y_data_test, [itr_test,1,1,N*N])\n",
    "#print(y_data_test.shape)\n",
    "y_data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the non zero values of Test output power so that there is some sizable error if the model outputs a zero matrix\n",
    "#scaling_parameter = 100\n",
    "\n",
    "y_data_test = y_data_test*scaling_parameter\n",
    "y_data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80677b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make predictions using our model\n",
    "import time\n",
    "t = time.perf_counter()\n",
    "y_pred = model.predict(X_data_test)\n",
    "elapsed = time.perf_counter() - t\n",
    "print(elapsed)\n",
    "print(y_pred.shape)\n",
    "print(\"For 1 prediction\")\n",
    "print(elapsed/itr_test)\n",
    "t_c = t_c + elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time taken to train and predict one sample\n",
    "print(\"Total time taken to train and predict all sample\")\n",
    "print(t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "model.evaluate(X_data_test, y_data_test)\n",
    "elapsed1 = time.perf_counter() - t1\n",
    "print(elapsed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(1,(6)+1)\n",
    "x_axis.shape\n",
    "ind = 3\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[ind]/scaling_parameter)\n",
    "y_data_test[ind]/scaling_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc206e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(0, itr_test))\n",
    "#for i in a:\n",
    "#    plt.figure()\n",
    "#    plt.plot(x_axis,y_data_test[i]/scaling_parameter,'b',x_axis,y_pred[i]/scaling_parameter,'r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.ylim((0.2, 1))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2be344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "#plt.ylim((20, 40))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/RBI_TL_SepTr_0.7_mean(30-11-2023)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

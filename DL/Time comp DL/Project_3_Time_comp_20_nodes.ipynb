{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our project\n",
    "\n",
    "# Here we are building a mulitple input mixed data model that takes in the 3 inputs seperately. RBI, chaneel matrices remain \n",
    "# seperate but now instead of giving Spectrum Occupancy matrix as input we give only NSA and instead of Src Des matrix we \n",
    "# just give Src and Des node id. The NSA and Src_Des input are given in two different branches, in the next model they will \n",
    "# be given together on one branch. The output power are indices rather matrices. So its an Nx1 vector.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# number of iterations the matlab code ran or the number of times the network is simulated\n",
    "itr = 171\n",
    "# Number of iterations the test data generation matlab code ran or the number of times the network is simulated\n",
    "itr_test = 15\n",
    "# number of nodes in the network\n",
    "N = 20\n",
    "# We scale the non zero values of output power so that there is some sizable error if the model outputs a zero matrix\n",
    "scaling_parameter = 1\n",
    "\n",
    "# Reading the RBI data\n",
    "df = pd.read_csv(\"Data_rbi_vectors_20.csv\")\n",
    "#print(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "tem = df.to_numpy()\n",
    "#print(tem)\n",
    "tem.shape\n",
    "\n",
    "#Just for the 1332 dataset as the last array will be nans\n",
    "#tem = tem[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94562fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(range(0, itr))\n",
    "X_1 = np.zeros((itr,N))\n",
    "for i in a:\n",
    "    X_1[i:] = tem[i:]\n",
    "#X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the channel data\n",
    "df1 = pd.read_csv(\"Data_channel_matrices_20.csv\")\n",
    "#print(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_2 = df1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2.reshape((itr,N,N))\n",
    "#print(X_2)\n",
    "X_2 = np.nan_to_num(X_2)\n",
    "#X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6164f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Source_Destination_info data\n",
    "df2 = pd.read_csv(\"Data_Source_Destination_info_matrix(only Src Des)_20.csv\")\n",
    "#print(df2)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b680ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_3 = df2.to_numpy()\n",
    "#print(X_3)\n",
    "X_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = X_3.astype(np.float64)\n",
    "print(X_3.dtype)\n",
    "#print(X_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Spectrum_occupancy data, i.e, NSA\n",
    "df3 = pd.read_csv(\"Data_spectrum_matrix_20.csv\")\n",
    "#print(df3)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ada01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_4 = df3.to_numpy()\n",
    "#print(X_4)\n",
    "X_4.shape\n",
    "\n",
    "# Its already in float64 so no need to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the output power data\n",
    "df4 = pd.read_csv(\"Data_output1_20.csv\")\n",
    "#print(df4)\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5598e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_5 = df4.to_numpy()\n",
    "#print(X_5)\n",
    "print(X_5.shape)\n",
    "X_5 = np.nan_to_num(X_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e513a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = X_5.astype(np.float64)\n",
    "print(y_data.dtype)\n",
    "#print(y_data_temp)\n",
    "y_data.shape\n",
    "\n",
    "# No need to unravel it as its already a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.dtype, X_2.dtype, X_3.dtype, X_4.dtype, y_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.shape, X_2.shape, X_3.shape, X_4.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling parameter for y_data so model gets greater penalty for error and also since output is sparse\n",
    "\n",
    "y_data = y_data*scaling_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_data to tensor\n",
    "\n",
    "y_data = tf.constant(y_data)\n",
    "print(y_data.shape)\n",
    "#y_data = tf.reshape(y_data, [itr,1,1,N*N])\n",
    "#print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.core import Activation\n",
    "from tensorflow.python.keras.layers.core import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import concatenate\n",
    "#from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating branches of the model\n",
    "\n",
    "# Activations\n",
    "a1 = 'relu'\n",
    "a2 = None\n",
    "\n",
    "# Branch 1, takes RBI vectors as input and processws it\n",
    "\n",
    "rbi_input = Input(shape=(N,))\n",
    "x1 = Dense(15, activation=a1)(rbi_input)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = Dense(15, activation=a1)(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "#x1 = Dense(1000, activation=a2)(x1)\n",
    "#x1 = Dense(1000, activation=a2)(x1)\n",
    "out_1 = Dense(N, activation=a1)(x1)\n",
    "\n",
    "# Branch 2, takes channel matrix as input and processes it\n",
    "\n",
    "chan_input = Input(shape=(N, N))\n",
    "#x2 = Flatten()(chan_input)\n",
    "x2 = Dense(20, activation=a1)(chan_input)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(20, activation=a1)(x2)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "#x2 = Dense(1000, activation =a2)(x2)\n",
    "#x2 = Dense(1000, activation =a2)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "out_2 = Dense(N*N, activation=a1)(x2)\n",
    "\n",
    "# Branch 3, takes Source Destination info and processes it\n",
    "\n",
    "S_D_input = Input(shape=(2, ))\n",
    "#x3 = Flatten()(S_D_input)\n",
    "x3 = Dense(5, activation=a1)(S_D_input)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = Dense(5, activation=a1)(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "#x3 = Dense(1000, activation =a2)(x3)\n",
    "#x3 = Dense(1000, activation =a2)(x3)\n",
    "#x3 = Flatten()(x3)\n",
    "out_3 = Dense(10, activation=a1)(x3)\n",
    "\n",
    "# Branch 4, takes Spectrum occupancy info and processes it\n",
    "\n",
    "Spec_input = Input(shape=(1, ))\n",
    "#x4 = Flatten()(Spec_input)\n",
    "x4 = Dense(5, activation=a1)(Spec_input)\n",
    "x4 = Dropout(0.2)(x4)\n",
    "x4 = Dense(5, activation=a1)(x4)\n",
    "x4 = Dropout(0.2)(x4)\n",
    "x4 = tf.keras.layers.BatchNormalization()(x4)\n",
    "#x4 = Dense(1000, activation =a2)(x4)\n",
    "#x4 = Dense(1000, activation =a2)(x4)\n",
    "#x4 = Flatten()(x4)\n",
    "out_4 = Dense(10, activation=a1)(x4)\n",
    "\n",
    "# Now we concatenate all the branches \n",
    "\n",
    "concatenated = concatenate([out_1, out_2, out_3, out_4]) ## concatenate the four branches\n",
    "x5 = Dense(20, activation=a1)(concatenated)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "x5 = Dense(20, activation=a1)(x5)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "x5 = Dense(20, activation=a1)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "#x5 = Dense(2000, activation=a2)(x5)\n",
    "out = Dense(N, activation=a1)(x5)\n",
    "model = Model([rbi_input, chan_input, S_D_input, Spec_input], out, name='Model_3')\n",
    "\n",
    "# Set optimizer\n",
    "\n",
    "#opt = Adam(lr=0.01, decay=1e-6)\n",
    "#sgd = SGD(lr=0.0, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss=tf.keras.losses.mse,\n",
    "#              optimizer=tf.keras.optimizers.Adam(),\n",
    "#              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit([X_1, X_2, X_3, X_4], y_data, batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we read the test data to evaluate our model\n",
    "\n",
    "\n",
    "# Reading the Test RBI data\n",
    "df_test = pd.read_csv(\"Test_Data_rbi_vectors_20.csv\")\n",
    "#print(df_test)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e54ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "tem_test = df_test.to_numpy()\n",
    "#print(tem_test)\n",
    "tem_test.shape\n",
    "X_1_test = tem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc551c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test channel data\n",
    "df1_test = pd.read_csv(\"Test_Data_channel_matrices_20.csv\")\n",
    "#print(df1_test)\n",
    "df1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ce88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_2_test = df1_test.to_numpy()\n",
    "X_2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_test = X_2_test.reshape((itr_test,N,N))\n",
    "#print(X_2_test)\n",
    "X_2_test = np.nan_to_num(X_2_test)\n",
    "#X_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test Source_Destination_info data\n",
    "\n",
    "df2_test = pd.read_csv(\"Test_Data_Source_Destination_info_matrix(only Src Des)_20.csv\")\n",
    "#print(df2_test)\n",
    "df2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c06566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_3_test = df2_test.to_numpy()\n",
    "#print(X_3_test)\n",
    "X_3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_test = X_3_test.astype(np.float64)\n",
    "print(X_3_test.dtype)\n",
    "#print(X_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea766d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test Spectrum_occupancy data, i.e, NSA\n",
    "\n",
    "df3_test = pd.read_csv(\"Test_Data_spectrum_matrix_20.csv\")\n",
    "#print(df3_test)\n",
    "df3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_4_test = df3_test.to_numpy()\n",
    "#print(X_4_test)\n",
    "X_4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fe49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4_test = X_4_test.astype(np.float64)\n",
    "print(X_4_test.dtype)\n",
    "#print(X_4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test output power data\n",
    "\n",
    "df4_test = pd.read_csv(\"Test_Data_output1_20.csv\")\n",
    "#print(df4_test)\n",
    "df4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverting it into numpy array\n",
    "X_5_test = df4_test.to_numpy()\n",
    "#print(X_5_test)\n",
    "print(X_5_test.shape)\n",
    "X_5_test = np.nan_to_num(X_5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab61b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_test = X_5_test.astype(np.float64)\n",
    "print(y_data_test.dtype)\n",
    "#print(y_data_test)\n",
    "y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test.dtype, X_2_test.dtype, X_3_test.dtype, X_4_test.dtype, y_data_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test.shape, X_2_test.shape, X_3_test.shape, X_4_test.shape, y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test = [X_1_test, X_2_test, X_3_test, X_4_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_data_test to tensor\n",
    "\n",
    "y_data_test = tf.constant(y_data_test)\n",
    "print(y_data_test.shape)\n",
    "#y_data_test = tf.reshape(y_data_test, [itr_test,1,1,N*N])\n",
    "#print(y_data_test.shape)\n",
    "y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the non zero values of Test output power so that there is some sizable error if the model outputs a zero matrix\n",
    "#scaling_parameter = 100\n",
    "\n",
    "y_data_test = y_data_test*scaling_parameter\n",
    "y_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80677b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make predictions using our model\n",
    "import time\n",
    "\n",
    "t = time.perf_counter()\n",
    "y_pred = model.predict(X_data_test)\n",
    "elapsed = time.perf_counter() - t\n",
    "print(elapsed)\n",
    "print(y_pred.shape)\n",
    "print(\"For 1 prediction\")\n",
    "print(elapsed/itr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "model.evaluate(X_data_test, y_data_test)\n",
    "elapsed1 = time.perf_counter() - t1\n",
    "print(elapsed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(1,(N)+1)\n",
    "x_axis.shape\n",
    "ind = 3\n",
    "print(y_pred[ind]/scaling_parameter)\n",
    "y_data_test[ind]/scaling_parameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
